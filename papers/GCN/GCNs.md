# Graph Convolutional Networks(GCNs)

## Definitions

当前大多数图神经网络模型普遍都有一种全局的架构，我称之为图卷积网络(GCNs)；卷积，因为滤波器的参数在图的全部位置都共享。

这些模型的目标是在图$\mathcal{G=(V,E)}$上学到一个关于信号或者特征的函数，其接收的输入为：

* 每个节点$i$的特征描述$x_i$;聚合成一个$N\times D$的特征矩阵$X$，$N$为节点的个数，$D$为输入特征的维度
* 一个矩阵形式的图结构的描述；一般以邻接矩阵$A$的形式（或者它的某些函数）

并产生一个节点级的输出$Z$（是一个$N\times F$的特征矩阵，其中$F$是每个节点的输出特征的维度）。图级别的输出可以通过引入某些形式的池化操作来建模。

每个神经网络层都可以写成一个非线性函数
$$
H^{(l+1)}=f(H^{(l)},A),
$$
$H^{(0)}=X,H^{(L)}=Z$（或者对于图级别的输出为$z$），$L$是层数。具体的模型之间的差比仅在于$f(\cdot, \cdot)$的选择和参数化上。