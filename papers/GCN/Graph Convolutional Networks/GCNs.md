# Graph Convolutional Networks(GCNs)

http://tkipf.github.io/graph-convolutional-networks/

## Definitions

当前大多数图神经网络模型普遍都有一种全局的架构，我称之为图卷积网络(GCNs)；卷积，因为滤波器的参数在图的全部位置都共享。

这些模型的目标是在图$\mathcal{G=(V,E)}$上学到一个关于信号或者特征的函数，其接收的输入为：

* 每个节点$i$的特征描述$x_i$;聚合成一个$N\times D$的特征矩阵$X$，$N$为节点的个数，$D$为输入特征的维度
* 一个矩阵形式的图结构的描述；一般以邻接矩阵$A$的形式（或者它的某些函数）

并产生一个节点级的输出$Z$（是一个$N\times F$的特征矩阵，其中$F$是每个节点的输出特征的维度）。图级别的输出可以通过引入某些形式的池化操作来建模。

每个神经网络层都可以写成一个非线性函数
$$
H^{(l+1)}=f(H^{(l)},A),
$$
$H^{(0)}=X,H^{(L)}=Z$（或者对于图级别的输出为$z$），$L$是层数。具体的模型之间的差比仅在于$f(\cdot, \cdot)$的选择和参数化上。



## A Simple Example

作为一个例子，考虑下面这个层级传播法则的非常简单的形式：
$$
f(H^{(l)},A)=\sigma \Big(AH^{(l)}W^{(l)}\Big),
$$
其中$W^{(l)}$是第$l$层的权重矩阵，$\sigma(\cdot)$是一个非线性激活函数，比如$\textbf{ReLU}$. 尽管它的形式很简单，但是这个模型已经很强大了。

但是首先，让我们明确关于这个模型的两个局限：与$A$的乘法意味着对每个节点，将其所有邻居的特征向量进行加和，但是不包括它本身（除非图中存在自循环）。可以通过在图中强制加入自循环来进行“改进”：只需要将单位矩阵加到$A$上即可。

第二个主要的局限是$A$一般是未经归一化的，因此与$A$的乘法可能改变特征向量的值域范围（可以通过查看$A$的特征值来理解）。将$A$归一化成每一行的加和为1，如$D^{-1}A$，其中$D$是对角的顶点度矩阵，可以解决这个问题。现在乘以$D^{-1}A$相当于对邻居节点的特征取平均。实际上当使用一种对称的归一化$D^{-\frac{1}{2}}AD^{-\frac{1}{2}}$时，dynamics变得更有趣（因为这个的和不再仅仅是相邻节点的平均）。合并这两个tricks，基本就得到了<SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS>中引入的传播法则：
$$
f(H^{(l)},A)=\sigma \Big(\hat{D}^{-\frac{1}{2}} \hat{A}\hat{D}^{-\frac{1}{2}} H^{(l)}W^{(l)} \Big),
$$
$\hat{A}=A+I$，其中$I$是单位矩阵，$\hat{D}$是$\hat{A}$的对角度矩阵。



## Embedding the karate club network

看一下上述的这个简单的GCN模型在一个广为人知的图数据集：Zachary's karate club network上的表现如何。

![karate](karate.png"karate")



使用一个3层的GCN，随机初始化权重。现在，在训练权重之前，仅将图的邻接矩阵和$X=I$（单位矩阵，因为我们没有任何节点特征）输入到模型中。这个3层的GCN在前向传播阶段执行三个传播步骤，有效地对每个节点进行三阶卷积（所有节点都到3“跳”之外）。值得注意的是，模型生成一个关于这些节点的embedding，其与图的社区结构(community-structure???)非常相近（见下图）。注意我们是通过随机初始化的权重，而且目前为止并没有进行训练和更新。

![karate_emb](karate_emb.png"karate_emb")

这个结果依序看起来有些令人感到惊讶。最近有一篇关于一个校准DeepWalk模型的文章展示了它们可以在一个复杂的无监督训练过程中学习到一个很类似的embedding. 怎么可能使用我们没有经过训练的的简单GCN模型获得这样的embedding？

我们可以通过将GCN解释成一个作用于图上的泛化且可微版的Weisfeiler-Lehman算法来阐明这一现象。一维的Weisfeiler-Lehman算法的机制为：

