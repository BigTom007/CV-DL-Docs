# A Style-Based Generator Architecture for Generative Adversarial Networks

**Abstract** 提出一个用于生成对抗网络的可替代的生成器架构，借鉴于风格迁移作品。新架构能够得到自动学习，无监督的分离的高级特征（例如用于人脸生成中的姿态、id等）和生成的图片中的随机变量（如雀斑、头发），并对合成具有直观且尺度特定的控制能力。新的生成器在传统分布质量度量上达到sota，明确地更好的内部属性，同时更好地对变量潜在的影响因素进行解耦。



# 1. Introduction

GAN生成的图像的分辨率和质量持续提升。但是生成器仍然如黑盒一样，仍然缺少对图片合成过程中的不同方面的理解，如初始随机特征等。人们对隐空间（latent space）的理解同样很少，常见的展示隐空间的方法（? interpolations）也没有提供比较不同生成器的量化方法。

受风格迁移启发，重新设计了生成器的架构，暴露新方式用于控制图像合成过程。我们的生成器从一个学习后的常量输入开始，没一个卷积层基于隐编码调整图像的“风格”，从而直接控制不同尺度上图像特征的强度。与直接注入网络的噪音结合，这个结构上的改变获得了随机变量的高级属性的自动的、无监督的分离。并没有改变判别器和loss函数。

将输入的隐编码嵌入到一个中间隐空间中，这样做对网络如何表达变量有很大效果。输入隐空间必须遵循训练数据的概率密度，但是我们主张这一结论在某种程度上会导致无法避免的耦合。我们的中间隐空间就不受这个限制，因此可以解耦。由于以前估计隐空间解耦程度的方法不能直接应用于我们的案例，所以提出两个新的自动度量：**感知路径长度**和**线性分离度**，用于量化生成器的这些方面。



# 2. Style-based generator

一般来讲都是通过一个输入层将隐编码传入生成器的，例如前向网络的第一层，如Fig 1a所示。我们不采用这种方法，而是将输入层全部省略，从一个可学习的常量开始，如Fig 1b所示。给定一个属于输入隐空间$\mathcal{Z}$的隐编码$\textbf{z}$,首先经过一个非线性映射网络$f:\mathcal{Z} \to \mathcal{W}$生成$\textbf{w}\in \mathcal{W}$. 简单起见，将两个空间的维度都设定为512，映射$f$使用的是一个8层的MLP. 学习一个仿射变换，然后获取属于*风格*$\textbf{y}=(\textbf{y}_s, \textbf{y}_b)$的特定的$\textbf{w}$用于控制g网络每个卷积层之后的AdaIN(adaptive instance normalization)操作。AdaIN操作定义为：
$$
\mathrm{AdaIN}(\textbf{x}_i, \textbf{y})=\textbf{y}_{s,i} \frac{\textbf{x}_i-\mu(\textbf{x}_i)}{\sigma(\textbf{x}_i)} + \textbf{y}_{b,i}, \qquad(1)
$$
其中每个特征图$\textbf{x}_i$是分开进行归一化的，然后使用对应风格$\textbf{y}$的缩放组件进行缩放和添加偏置。因此，$\textbf{y}$的维度是那一层特征图维度的两倍。

![Figure 1](1.png"Figure 1")

与风格迁移相比，我们根据向量$\textbf{w}$而非风格图片计算了空间不变的风格参数$\textbf{y}$. 



blahblahblah



## 3. Properties of the style-based generator

我们的生成器通过对风格的特定尺度修改实现对图像合成的控制。可以将映射网络和放射变化视为一种从一个学习的分布中对每种风格获取样本的方法，将合成网络视为生成一张基于一个风格集合生成一张新图片的方法。每种风格的作用都被定位在网络中，例如修改风格的一个特定子集合只会影响生成图像的几个特定方面。

要得到如此定位的原因，考虑AdaIN操作，其首先将每个通道归一化到0均值和单位方差，然后才根据风格加上尺度和偏置。新的到的每个通道的统计信息受风格支配，会修改用于随后卷积操作的相关特征的重要程度，但是不依赖于原始统计信息，因为经过了归一化。因此每个风格在被下一个AdaIN操作覆盖之前只控制一个卷积层。



### 3.1. Style mixing

使用混合正则化进一步增强风格定位，在训练过程中，给定百分比的图像使用两个随机隐编码而非一个生成。当生成一张图片的时候，在合成网络的某个随机的位置，将隐编码从一个换成另一个，这个操作称为风格混合。具体说，将两个隐编码$\textbf{z}_1,\textbf{z}_2$传入映射网络，得到对应的$\textbf{w}_1,\textbf{w}_2$用于控制风格，在交叉点(crossover point)之前使用$\textbf{w}_1$，之后使用$\textbf{w}_2$. 这个正则化技术可以防止网络假定相邻的风格具有相关性。Fig 3展示了通过混合几个尺度的两个隐编码合成的图片样本。可以看到每个风格的子集都控制图像有意义的高级属性。

![Figure 3](3.png"Figure 3")

### 3.2. Stochastic variation

人像的很多方面都有随机性，例如头发的具体位置、胡茬、雀斑或者毛孔。对于这些方面来说，只要它们遵循正确的分布，就可以在不影响我们对图像的感知的条件下随机生成。

考虑一下一个传统的生成器如何实现随机变化。通过输入层给定网络的唯一输入，网络需要找到一种方式，当需要的时候，从先前的活动生成空间变化的伪随机数。这样做会消耗网络能力，而且隐藏生成的信号周期很困难——且不保证成功，证据可从生成图像中常见的重复模式找到。我们的架构通过在每次卷积后对每个像素增加噪音的方式避免这些问题。

![Figure 4](4.png"Figure 4")

Fig 4展示了同一张基础图片使用我们的生成器加不同的噪音生成的随机变化。可以看到噪音只影响随机的方面，而不影响整体整体构成和高级方面例如id信息。Fig 5进一步展示了对不同层的子集合使用随机变化的效果。

![Figure 5](5.png"Figure 5")

有趣的是，我们发现噪声的影响在网络中的定位非常紧密。假设在生成器的任意位置，尽可能早地引入新的内容都有压力阻碍，网络创建随机变化的最简单的方式就是依赖于提供的噪声。每一层都可以获得一组新的噪声，因此也就不需要根据之前的活动生成随机效果。

### 3.3. Separation of global effects from stochasticity

