# ByeGlassesGAN

用于去掉眼镜的GAN框架



## 1 Introduction

blahblahblah



## 2 Related Work

blahblahblah



## 3 ByeGlassesGAN

提出一个用于预测眼镜位置并将其从源图像上移除的多任务学习方法。

### 3.1 Proposed Framwork

![Figure 2](2.png"Figure 2")

Figure 2展示了ByeGlassesGAN整体框架，其包含一个生成器，一个身份提取器和两个判别器。生成器(G)可以分成三个深度神经网络：编码器(E)，面部解码器(FD)和分割解码器(SD). 在这里我们假设训练数据包含一组人脸图片(x)和对应的去除眼镜后的图片(y)、对应眼镜区域的mask以及完整的面部形状。给定一张源人脸图片$x$，首先经过编码器编码特征向量。然后使用面部解码器根据编码得到的特征向量合成一张去掉眼镜的图片$\hat{y}$. 同时，分割解码器生成眼镜区域的mask$\hat{m}$. 但是在对这个baseline模型进行测试后我们发现尽管有很多效果良好的去除结果，但是当眼镜比较特别或人脸不是正脸的时候效果会下降。因此怀疑是否存在一个好的人脸表达可以帮助移除眼镜。由于移除眼睛可被视为一种人脸区域的图像修复任务，可以引入人脸和眼镜区域的语义分割mask到框架中。人脸形状的分割是引导FD（面部解码器）了解面部区域中的每个像素的角色并且相邻像素间应该保持一致性的很好的线索。实验后发现，让SD（分割编码器）预测面部形状的binary mask同样可以大幅度提高眼镜移除结果的效果。因此让SD不仅预测眼镜区域的binary mask，同时也预测面部形状的binary mask. 另外，从SD获取的信息同样使用跳跃连接与FD进行共享来知道FD合成图像。因此就有
$$
\hat{y}=FD(E(x)) \qquad (1)\\
\hat{m}=SD(E(x)) \qquad(2)
$$
其中$\hat{m}$是一个两通道的mask，一个通道代表眼镜区域，另一个代表人脸形状。而且为了保证合成输出$\hat{y}$的质量，使用一个全局判别器和一个局部判别器来保证合成图像$\hat{y}$和修复后的眼镜框区域$\hat{y}_{Local}$看起来真实。另外同样引入一个身份提取器来最小化输出图片($\hat{y}$)和gt图片($y$)身份特征向量的距离。

### 3.2 Objective Function

目标函数由四个loss函数组成，即对抗loss，像素loss，分割loss和id保持loss. 

**Adversarial Loss** 为了使生成的图片尽可能的真实，采用对抗学习的策略。