# A Discriminative Feature Learning Approach for Deep Face Recognition

为了提高深度学习特征的分辨能力，提出人脸识别任务的一个新监督信号，CenterLoss，它同时对每个类别的深度特征学习一个中心并对特征和对应类别中心间的距离进行惩罚。在softmax loss和center loss的联合监督下，可以训练一个鲁棒的CNN用来获取深度特征，其具有两个关键学习目标，尽可能的类间分散和类内紧凑。



## 1 Introduction

最常使用的CNN可以实现特征学习和标签的预测，其将输入数据映射到深度特征（最后隐藏层的输出），然后输出预测的标签，如Figure 1所示。

![Figure 1](1.png"Figure 1")

对于一般的物体、场景或动作识别任务，测试样本中可能出现的类别都包含在训练集中了，也称为封闭集合识别(close-set identification)。因此，预测的标签控制其性能而softmax loss可以直接解决分类问题。这样，标签的预测就和一个线性分类器差不多，学到的特征也倾向于可分离。

对于人脸识别任务，深度学习特征不仅需要是可分离的，还需要是具有分辨性的。因为预先收集好训练中所有可能的测试id是不现实的，所以CNN中的标签预测并不总是可应用的。深度学习的特征需要具有足够强的分辨性和泛化性来识别新的、未见过且没有标签的类别。特征的分辨能力同时体现在紧凑的类内偏差和分离的类间差异上，见Figure 1. 对于具有分辨性的特征可以使用NN或kNN算法分类，而不需要依赖标签的预测。但是softmax loss只能促进特征的可分离性。得到的特征对于人脸识别来说有效性不够。

为CNN有分辨性的特征学习构建高效损失函数是很有意义的。因为SGD基于mini-batch优化CNN，它无法很好地反映深度特征的全局分布。由于训练集数据量巨大，将所有训练样本放入每个循环中是不现实的。替代思路包括对抗loss和triplet loss，分别对图像对和三元组构建loss函数。但是与图像样本相比，训练图像对或者三元组的数量增长地非常夸张。这样必然导致收敛缓慢和不稳定。当然可以通过细心挑选图像对或三元组来部分缓解这一问题。但是这样做会极大增加计算复杂度，而且训练过程会变困难。

本文提出一个新的损失函数称为center loss，目的是高效地增强神经网络深度特征的分辨能力。对每个类别的深度特征学习一个中心（一个与特征向量同维度的向量）。在训练的时候，同步更新中心并最小化深度特征和对应类中心的距离。使用softmax loss 和center loss的联合监督来训练CNN，使用一个超参数来平衡两个监督信号。直观理解，softmax loss强制不同类别间保持距离。center loss将同一类别的特征向其中心靠近。



## 2 Related Work

blahblahblah



## 3 The Proposed Approach

### 3.1 A Toy Example

blahblahblah

### 3.2 The Center Loss

那么如何开发一个高效的loss函数来增强特征的分辨能力呢？直观地讲，关键是在最小化类内偏差的同时保持不同类别特征分离。为了实现这一目的，提出center loss函数：
$$
\mathcal{L}_C=\frac{1}{2}\sum\limits_{i=1}^m \Vert x_i - c_{y_i} \Vert_2^2 \qquad(2)
$$
